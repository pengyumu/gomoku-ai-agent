# -*- coding: utf-8 -*-
"""student_llm_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FJPhphC__FniwFz6S1NQaduXutxSJVag
"""

# student_llm_agent.py
# A discoverable LLM Gomoku agent using an OpenAI-compatible API (e.g., Groq/Together)

import os
import re
import json
import random
from typing import Tuple, Optional

from gomoku import Agent
from gomoku.llm import OpenAIGomokuClient
from gomoku.core.models import GameState

class StudentLLMAgent(Agent):
    """
    LLM-based Gomoku agent (8x8, five-in-a-row) using an OpenAI-compatible API.
    - Default provider: Groq (OpenAI-compatible)
    - Default model: Qwen3-8B (可按实际可用名称调整)
    - Strict JSON output & legal-moves constraint
    """

    def __init__(
        self,
        agent_id: str,
        *,
        model: str = None,
        endpoint: str = None,
        api_key_env: str = None
    ):
        # 允许从环境变量覆盖默认配置
        self._model = model or os.getenv("GOMOKU_LLM_MODEL", "qwen3-8b")
        self._endpoint = endpoint or os.getenv("GOMOKU_LLM_ENDPOINT", "https://api.groq.com/openai/v1")
        # 可改成 "TOGETHER_API_KEY" 等
        self._api_key_env = api_key_env or os.getenv("GOMOKU_LLM_API_KEY_ENV", "GROQ_API_KEY")
        super().__init__(agent_id)

    # ------------------------------------------------------------------ setup

    def _setup(self):
        """Init LLM client & system prompt."""
        self.system_prompt = self._create_system_prompt()

        api_key: Optional[str] = os.getenv(self._api_key_env)
        if not api_key:
            print(f"⚠️  No {self._api_key_env} in environment; will use fallback moves.")
            self.llm_client = None
        else:
            self.llm_client = OpenAIGomokuClient(
                api_key=api_key,
                model=self._model,
                endpoint=self._endpoint,
            )

    # --------------------------------------------------------------- prompts

    def _create_system_prompt(self) -> str:
        """Global rules + strict output."""
        return (
            "You are a competitive Gomoku expert playing on an 8×8 board (0-indexed).\n"
            "Goal: get five-in-a-row (horizontal/vertical/diagonal). Never overwrite stones.\n\n"
            "STRICT OUTPUT:\n"
            '- Return ONE line of JSON ONLY, no extra text, no code fences.\n'
            '- Schema: {\"row\": <int>, \"col\": <int>}\n'
            "- The move MUST be chosen from LEGAL_MOVES.\n\n"
            "MOVE PRIORITY (highest→lowest):\n"
            "1) Win-in-1: if you can complete five, do it now.\n"
            "2) Block-in-1: if opponent can complete five next, block it now.\n"
            "3) Create immediate threat: make/extend an open four.\n"
            "4) Dual threats: create two simultaneous open threes if possible.\n"
            "5) Extend/bridge your longest chain with open ends.\n"
            "6) Centrality & flexibility when ties remain.\n"
            "7) Final tiebreaker: pick the earliest item in LEGAL_MOVES.\n\n"
            "SELF-CHECK:\n"
            "- If your chosen cell is NOT in LEGAL_MOVES, output the first item of LEGAL_MOVES "
            "that best matches the above priority, as JSON."
        )

    def _build_user_prompt(self, game_state: GameState, legal_moves):
        """提供当前局面 + 执子方 + 合法落子列表（降低非法概率）"""
        board_str = game_state.format_board("standard")
        you = game_state.current_player.value  # 'X' or 'O'
        opp = 'O' if you == 'X' else 'X'
        legal_list = [[r, c] for (r, c) in legal_moves]
        return (
            f"BOARD (8x8, 0-indexed):\n{board_str}\n\n"
            f"you_play: {you}\n"
            f"opponent: {opp}\n\n"
            f"LEGAL_MOVES: {legal_list}\n"
            f"Output JSON only."
        )

    # --------------------------------------------------------------- helpers

    def _safe_extract_json(self, text: str):
        """先整体 loads；失败则正则提取第一个 {…} 并清洗常见尾逗号。"""
        try:
            return json.loads(text)
        except Exception:
            pass
        m = re.search(r"\{.*\}", text, re.DOTALL)
        if not m:
            return None
        block = m.group(0)
        try:
            return json.loads(block)
        except Exception:
            cleaned = re.sub(r",\s*}", "}", block)
            try:
                return json.loads(cleaned)
            except Exception:
                return None

    def _fallback_move(self, game_state: GameState) -> Tuple[int, int]:
        """兜底落子：选择离中心最近的合法点（比随机更稳健）。"""
        legal = game_state.get_legal_moves()
        if not legal:
            center = game_state.board_size // 2
            return (center, center)
        center = game_state.board_size // 2
        return min(legal, key=lambda rc: abs(rc[0]-center) + abs(rc[1]-center))

    # ------------------------------------------------------------------ core

    async def get_move(self, game_state: GameState) -> Tuple[int, int]:
        """让 LLM 给出下一步；含严格合法性校验与兜底。"""
        legal_moves = game_state.get_legal_moves()
        if not legal_moves:
            return self._fallback_move(game_state)

        # 无 Key 或未初始化 client → 直接兜底
        if self.llm_client is None:
            return self._fallback_move(game_state)

        try:
            user_prompt = self._build_user_prompt(game_state, legal_moves)
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user",   "content": user_prompt},
            ]

            response = await self.llm_client.complete(
                messages,
                temperature=0.2,
                top_p=0.9,
                max_tokens=16,  # 仅一行 JSON
            )

            data = self._safe_extract_json(response) or {}
            r, c = data.get("row"), data.get("col")

            legal_set = set(legal_moves)
            if isinstance(r, int) and isinstance(c, int) and (r, c) in legal_set:
                return (r, c)

            return self._fallback_move(game_state)

        except Exception:
            return self._fallback_move(game_state)